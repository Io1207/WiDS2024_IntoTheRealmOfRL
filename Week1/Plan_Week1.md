# Week 1: Introduction to Numpy and Multi-Armed Bandits (MAB)

Welcome to Week 1 of the **Winter in Data Science: Into the Realm of RL** program! This week, we’ll cover the basics of the `numpy` library, an essential tool for efficient data manipulation, and introduce you to the fundamentals of Reinforcement Learning (RL) through the Multi-Armed Bandit (MAB) problem.

## Learning Objectives

1. **Numpy**: Get comfortable with basic Numpy operations, which will form the foundation for data processing in RL algorithms.
2. **Introduction to RL**: Understand the core concepts of RL and its applications.
3. **Multi-Armed Bandit Problem**: Explore the MAB problem as a foundational RL challenge, focusing on the Epsilon-Greedy approach for action selection.

---

## Weekly Resources

### Numpy Tutorial

**Goal**: Build a solid foundation in `numpy` so you can efficiently handle arrays and mathematical operations.

- **Tutorial**: [Geeks for Geeks Numpy Tutorial](https://www.geeksforgeeks.org/numpy-tutorial/)
- **Assignment**: After completing the tutorial, proceed to the [NumpyAssignment.ipynb](./NumpyAssignment.ipynb) in this folder. This assignment will test your understanding of Numpy basics and reinforce the concepts covered in the tutorial.

### Reading Exercise: Introduction to Reinforcement Learning (RL)

This section will introduce you to the basics of RL, setting the stage for understanding the Multi-Armed Bandit problem.

1. **Slides**: David Silver’s [Lecture 1](../Resources/David%20Silver%20Slides/lec1.pdf) from the `David Silver Slides` folder
2. **Textbook**: [Chapter 1](../Resources/SuttonBartoIPRLBook2ndEd.pdf) from *Sutton & Barto’s Introduction to Reinforcement Learning* (2nd Edition)
3. **Online Article**: [Introduction to Reinforcement Learning on Geeks for Geeks](https://www.geeksforgeeks.org/what-is-reinforcement-learning/)

These resources cover the essential principles of RL, including key concepts, terminology, and applications.

### Multi-Armed Bandit (MAB) Problem

The MAB problem is a simple yet powerful example in RL that illustrates how to handle exploration and exploitation. You’ll learn about the Epsilon-Greedy approach, a common strategy to solve the MAB problem.

1. **Slides**: David Silver’s [Lecture 9](../Resources/David%20Silver%20Slides/lec9.pdf) from the `David Silver Slides` folder
2. **Textbook**: Section 2.1 and 2.2 from [Chapter 2](../Resources/SuttonBartoIPRLBook2ndEd.pdf) of *Sutton & Barto’s Introduction to Reinforcement Learning* (2nd Edition)
3. **Additional Resource**: [Multi-Armed Bandit Problem Explanation](https://lilianweng.github.io/posts/2018-01-23-multi-armed-bandit/)

These readings will give you a theoretical and practical understanding of the MAB problem and prepare you for future work in RL.

---

## Assignments

- **Numpy Assignment**: Complete the `NumpyAssignment.ipynb` notebook after finishing the Numpy tutorial. This assignment will include exercises on array operations, reshaping, indexing, and other key Numpy functions.

---
